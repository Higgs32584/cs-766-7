{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fecc2e2",
   "metadata": {},
   "source": [
    "# 1. [20 pts] Considering two groups of reviews {sentiment 0, sentiment 1}, tokenize and lemmatize (here you can process in any way you want, such as removing contractions by regular expression, etc.) all the words in each group of reviews by combining all sentences, but not all reviews. As a result, we will have bags of words for each review and sentiment group. There must be 50,000 bags total. We neglected repetitions of the words in reviews. Compute the following: \n",
    "# Hint: Consider the event sample as the word being in the review or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c17bbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK library version= 3.8.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk import FreqDist\n",
    "print(f'NLTK library version= {nltk.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1911e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 234 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read the reviews and tokenize them - note the encoding\n",
    "reviews_sentiment_0  = []\n",
    "reviews_sentiment_1 = []\n",
    "with open('movie_data.csv','r',encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    next(reader)  # skip header\n",
    "    for line in reader:\n",
    "        if(line[1] == \"0\"):\n",
    "            reviews_sentiment_0 += [line[0]]\n",
    "        if(line[1] == \"1\"):\n",
    "            reviews_sentiment_1 += [line[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "262f51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.47 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sub_br_0  = [re.sub('<br />', ' ', review) for review in reviews_sentiment_0]\n",
    "sub_br_1  = [re.sub('<br />', ' ', review) for review in reviews_sentiment_1]\n",
    "_pat1 = r'(?i)[a-zA-Z]+(?=\\s|$)'\n",
    "\n",
    "sentences_sentiment_0  = [re.findall(_pat1, review) for review in sub_br_0]\n",
    "sentences_sentiment_1 = [re.findall(_pat1, review) for review in sub_br_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1b68ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean_sent(tokens_per_sentence):\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = SnowballStemmer('english')\n",
    "\n",
    "    # Apply stop word removal first\n",
    "    stop_tokens_per_sentence = [[token for token in review if token.lower() not in stop_words] for review in tokens_per_sentence]\n",
    "    stem_tokens_per_sentence = [[stemmer.stem(token) for token in review] for review in stop_tokens_per_sentence]\n",
    "    return stem_tokens_per_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2807b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 48s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_word_0=clean_sent(sentences_sentiment_0)\n",
    "cleaned_word_1=clean_sent(sentences_sentiment_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedd42e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.83 s\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "#Cleaned again because some Stop Words Got through\n",
    "list_of_bags_0=[set(review) for review in cleaned_word_0]\n",
    "list_of_bags_1=[set(review) for review in cleaned_word_1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b39cc9",
   "metadata": {},
   "source": [
    "# Probability('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcbb435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_of_bags=[list_of_bags_0,list_of_bags_1]\n",
    "def probability(word, sentiment=None):\n",
    "    if sentiment is not None:\n",
    "        prob_list_of_bags = [(word.lower() in freqDist) for freqDist in list_of_bags[sentiment]]\n",
    "        average_frequency = (sum(prob_list_of_bags) / len(prob_list_of_bags))\n",
    "    else:\n",
    "        prob_list_of_bags = [[(word.lower() in freqDist) for freqDist in sentiment_group] for sentiment_group in list_of_bags]\n",
    "        average_frequency = (sum(prob_list_of_bags[0]) + sum(prob_list_of_bags[1])) / (len(prob_list_of_bags[0]) + len(prob_list_of_bags[1]))\n",
    "    \n",
    "    return f\"Probability of '{word}': {average_frequency:.2%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e71c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 41.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Probability of 'good': 33.20%\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "probability('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820cad5f",
   "metadata": {},
   "source": [
    "# Probability('good' | sentiment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35045a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Probability of 'good': 33.52%\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability('good',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c709e",
   "metadata": {},
   "source": [
    "# Probability('good' | sentiment=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f12102f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Probability of 'good': 32.88%\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability('good',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef61ce",
   "metadata": {},
   "source": [
    "# Probability('good' and 'bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11144a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_both(word,word2):\n",
    "    prob_list_of_bags=[[(word.lower() in freqDist) and (word2.lower() in freqDist) for freqDist in sentiment_group] for sentiment_group in list_of_bags]\n",
    "    average_frequency=(sum(prob_list_of_bags[0])+sum(prob_list_of_bags[1]))/(len(prob_list_of_bags[0])+len(prob_list_of_bags[1]))\n",
    "    return f\"Probability of '{word}' and '{word2}': {average_frequency:.2%}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2996aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Probability of 'good' and 'bad': 8.87%\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_both('good','bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed70b9",
   "metadata": {},
   "source": [
    "# 2. [20 pts] According to this dataset and your NLP pipeline, is the word 'good' a good discriminator for sentiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e60014",
   "metadata": {},
   "source": [
    "According to this dataset, good is not a good discriminator for sentiments. This is because the prevalence of good in sentiment 1 vs sentiment 0 is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd4d90",
   "metadata": {},
   "source": [
    "# How about the word 'bad'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f80c464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Probability of 'bad': 10.36%\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability('bad',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "791651ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Probability of 'bad': 30.69%\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability('bad',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562773a",
   "metadata": {},
   "source": [
    "The word \"bad\" may be a good discriminator for sentiments, as the word \"bad\" appears in negative reviews 3x more than it appears in positive reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc027d",
   "metadata": {},
   "source": [
    "# 3. [20 pts] Compute the mutual information I('good', 'bad') in the IMDB dataset using your pipeline. \n",
    "# Hint: You must ignore the sentiments in this case and pool all reviews. Also see the hint in (Q1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f18f14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.37%'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def conditional_probability(A,B):\n",
    "    combined_list=list_of_bags[0]+list_of_bags[1]\n",
    "    prob_list_of_bags=[(A.lower() in review) and (B.lower() in review) for review in combined_list]\n",
    "    prob_of_A=[(A.lower() in review) for review in combined_list]\n",
    "    prob_of_B=[(B.lower() in review) for review in combined_list]\n",
    "    average_frequency=sum(prob_list_of_bags)/len(prob_list_of_bags)\n",
    "    average_A=sum(prob_of_A)/len(prob_of_A)\n",
    "    average_B=sum(prob_of_B)/len(prob_of_B)\n",
    "    if(average_A==0 or average_B == 0):\n",
    "        return f\"{0:.2%}\"\n",
    "    final_freq=average_frequency*math.log(average_frequency/(average_A*average_B),2)\n",
    "    return f\"{final_freq:.2%}\"\n",
    "conditional_probability('good','bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98548f10",
   "metadata": {},
   "source": [
    "# Comment on results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cac137f",
   "metadata": {},
   "source": [
    "According to the results, there appears to be little overlap between good and bad when it comes to the amount of mutual information that is shared between them. Since it is only 3.37%, I will say that the mutual information is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6a034",
   "metadata": {},
   "source": [
    "# 4. [20 pts] Compute the following mutual information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd89f89",
   "metadata": {},
   "source": [
    "# I('good', sentiment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cabc410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def conditional_probability_sentiment (A,B):\n",
    "    combined_list=list_of_bags[0]+list_of_bags[1]\n",
    "    small_list=list_of_bags[B]\n",
    "    A_in_sentiment = [(A.lower() in review) for review in small_list]\n",
    "    prob_of_A = [(A.lower() in review) for review in combined_list]\n",
    "    average_A=sum(prob_of_A)/50000\n",
    "    average_frequency=(sum(A_in_sentiment)/25000)/2\n",
    "    average_B = .5\n",
    "    final_freq=average_frequency*math.log(average_frequency/(average_A*average_B),2)\n",
    "#     if(final_freq<0):\n",
    "#         final_freq=0\n",
    "    return f\"{final_freq:.2%}\"\n",
    "conditional_probability_sentiment('good',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1fc91",
   "metadata": {},
   "source": [
    "# I('good', sentiment=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8846a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-0.23%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probability_sentiment('good',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbf2e4",
   "metadata": {},
   "source": [
    "# I('bad', sentiment=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b07737d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.91%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probability_sentiment('bad',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdf2ca",
   "metadata": {},
   "source": [
    "# I('bad', sentiment=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "025fac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-5.11%'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probability_sentiment('bad',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273634f",
   "metadata": {},
   "source": [
    "# Comment on your findings regarding question (Q2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad3e6b",
   "metadata": {},
   "source": [
    "My findings regarding question 2 versus question 4 solidify the various conclusions we have achieved in question 2. There was a minute difference between the prevalence of good in sentiment 1 and 0. With this, there is a .23% information rate between the two. Unsurprisingly, the information rate between good vs. sentiment one and bad vs. sentiment 1 was negative, as both had a more negligible prevalence of good and evil than sentiment 1. It also makes sense that the combination with the highest information rate was bad and sentiment 0, as we already knew that bad was 3x as prevalent in 0 vs. 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc64e08",
   "metadata": {},
   "source": [
    "# 5. [20 pts] What is the marginal entropy H(X) of a variable X, and what is the mutual information of X with itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6233a29",
   "metadata": {},
   "source": [
    "The marginal entropy of a variable H(X) of a variable X would be sigma(p(x)*log2(p(x))), where sigma represents the sum of the various outcomes, p(x) is the probability of a particular product for the specified x outcome, multiplied by log2(p(x)).\n",
    "Mutual information is the amount of information one variable knows about the other. We can determine mutual information as I(X;X) = H(X) - H(X|X), where H(X|X) is the conditional entropy, or how much information is needed on average to communicate the other variable. H(X) represents the chance of a particular outcome. Since, in this case, you are looking at the mutual information a variable contains about itself, there is no mutual information, as all information is self-information. Therefore, there is no conditional entropy either.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
