{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec7008e",
   "metadata": {},
   "source": [
    "# 1. [20 pts] In this step, we will develop a movie review vocabulary to be used as a baseline for processing movie reviews (such as newly posted) in our NLP pipeline. \n",
    "\n",
    "# First, discuss what could be the tools, approaches to find out most important keywords that give information about a review. For example, do you think such keywords should occur more in movie reviews compared to any other review of other items or events, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be3588",
   "metadata": {},
   "source": [
    "If we were to develop a movie review vocabulary to be used as a baseline for processing movie reviews, one of the first things that I would do is to identify is that we could first pre-process all of the reviews, using NLTK. We should remove the stopwords, and apply stemmers. Next, we should try to figure out what words occur most frequently in each distinct group of words. We should further remove additional stopwords that tend to occur in both good and bad reviews. When we do this, we can avoid information that would not be valuable for classifying the different words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fbdd9",
   "metadata": {},
   "source": [
    "# 2. [40 pts] Use the scikit-learn CountVectorizer to compute word frequencies. Find out the 30 most occurring words in reviews without dividing the set into {sentiment: 0, 1} grouping. This library function can use a tokenizer (you can pass your own tokenizer), and then use the complete reviews dataset to generate counts.\n",
    "\n",
    "\n",
    "Note that CountVectorizer generates a sparse matrix and we need to sum up column\n",
    "(terms) elements (each row is a document) for a particular term.\n",
    "Optional: You can also convert it to a regular matrix if your computing platform has enough\n",
    "memory and does not complain: X = X_cvec.todense()\n",
    "Use the following for fast column sum, which will probably be faster than the regular form:\n",
    "row_counts = sum(X_cvec[:,]) / N\n",
    "counts = np.squeeze(np.asarray(row_counts.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53865964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 312 ms\n",
      "Wall time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f0ea6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 328 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "# Read the reviews and tokenize them - note the encoding\n",
    "reviews_sentiment = []\n",
    "reviews_sentiment_w_sent = []\n",
    "with open('../movie_data.csv', 'r', encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    next(reader)  # skip header\n",
    "    lines = []\n",
    "    for line in reader:\n",
    "        reviews_sentiment.append(line[0])\n",
    "        reviews_sentiment_w_sent.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27b46e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    terms = word_tokenize(text)\n",
    "    # all lower case\n",
    "    terms = [w.lower() for w in terms]\n",
    "    # filter stop words\n",
    "    terms = [w for w in terms if w not in Stop_words and not w.isdigit()]\n",
    "    # remove contractions, best way might be having a list \n",
    "    terms = [w for w in terms if not re.search(r'^\\W\\w+$', w)]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215f4d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 22s\n",
      "Wall time: 3min 55s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>201951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>87971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>79705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>53603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>40172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>29753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>25110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>24871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>24602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>23119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>23094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>23029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>21268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>19318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>18473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>18421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>18188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>18144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>17977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>17583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>16152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>15899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>15645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>15565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>15309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>14456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>14337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>13947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>13905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>13755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "br          201951\n",
       "movie        87971\n",
       "film         79705\n",
       "one          53603\n",
       "like         40172\n",
       "good         29753\n",
       "time         25110\n",
       "even         24871\n",
       "would        24602\n",
       "story        23119\n",
       "really       23094\n",
       "see          23029\n",
       "well         21268\n",
       "much         19318\n",
       "bad          18473\n",
       "get          18421\n",
       "people       18188\n",
       "great        18144\n",
       "also         17977\n",
       "first        17583\n",
       "made         16152\n",
       "make         15899\n",
       "way          15645\n",
       "could        15565\n",
       "movies       15309\n",
       "characters   14456\n",
       "think        14337\n",
       "watch        13947\n",
       "character    13905\n",
       "films        13755"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cvec = CountVectorizer(stop_words=Stop_words)\n",
    "import pandas as pd\n",
    "\n",
    "X_cvec = cvec.fit_transform(reviews_sentiment)\n",
    "count_array = X_cvec.toarray()\n",
    "count_array=count_array.sum(axis=0)\n",
    "count_array = count_array.reshape(1, -1)\n",
    "df = pd.DataFrame(data=count_array,columns = cvec.get_feature_names_out())\n",
    "\n",
    "df=df.T\n",
    "df=df.sort_values(0,ascending=False)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4bc6a4",
   "metadata": {},
   "source": [
    "# What is X_cvec and what does it contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05184279",
   "metadata": {},
   "source": [
    "X_cvec contains a sparse matrix, where each row is a document, and each columnn represents the count of the various vocabulary words in each review. We can use this to count up the number of instances of particular words. We can use this for further analysis in question 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c4ba30",
   "metadata": {},
   "source": [
    "# 3. [20 pts] Use the following list to show if these keywords from a movie related web page actually match with the ones in our dataset (i.e., compared by frequencies or ranks):\n",
    "['script', 'soundtrack', 'actor', 'film', 'producer', 'director', 'special',\n",
    "'effect', 'score', 'cameraman', 'editor', 'blooper', 'box', 'office', 'cast',\n",
    "'choreographer', 'cinema', 'movie', 'theater', 'costumer', 'critic', 'dubbing',\n",
    "'extra', 'flashback', 'flash', 'forward', 'grip', 'hairstylist', 'lighting',\n",
    "'negative', 'outtake', 'premiere', 'sequel', 'puppeteer', 'reel', 'scene',\n",
    "'set', 'stunt', 'man', 'subtitle', 'synopsis', 'studio', 'squib', 'sound',\n",
    "'effect', 'voice', 'writer', 'zoom']\n",
    "(Source: https://www.vocabulary.com/lists/277003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e37fedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_keywords=['script', 'soundtrack', 'actor', 'film', 'producer', 'director', 'special', 'effect', 'score', 'cameraman', 'editor', 'blooper', 'box', 'office', 'cast', 'choreographer', 'cinema', 'movie', 'theater', 'costumer', 'critic', 'dubbing', 'extra', 'flashback', 'flash', 'forward', 'grip', 'hairstylist', 'lighting', 'negative', 'outtake', 'premiere', 'sequel', 'puppeteer', 'reel', 'scene', 'set', 'stunt', 'man', 'subtitle', 'synopsis', 'studio', 'squib', 'sound', 'effect', 'voice', 'writer', 'zoom']\n",
    "from nltk.corpus import reuters\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re \n",
    "# Combination of stop words and punctuations\n",
    "Stop_words = stopwords.words('english') + list(punctuation)\n",
    "def tokenize(text):\n",
    "    terms = word_tokenize(text)\n",
    "    # all lower case\n",
    "    terms = [w.lower() for w in terms]\n",
    "    # filter stop words\n",
    "    terms = [w for w in terms if w not in Stop_words and not w.isdigit()]\n",
    "    # remove contractions, best way might be having a list \n",
    "    terms = [w for w in terms if not re.search(r'^\\W\\w+$', w)]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b181a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 41s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Vocabulary = set()\n",
    "for review in reviews_sentiment:\n",
    "    terms = tokenize(review)\n",
    "    Vocabulary.update(terms)  # add multiple terms at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eac01b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size= 156921\n",
      "Reuters documents count N= 50000\n",
      "Vocabulary size= 156921\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 94.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Re-structure Vocabulary to a list so we can use indices to efficiently represent terms\n",
    "# Term_index will be used later in TfidfVectorizer\n",
    "Vocabulary = list(Vocabulary)\n",
    "Term_index = {w: idx for idx, w in enumerate(Vocabulary)}\n",
    "\n",
    "print(f'Vocabulary size= {len(Vocabulary)}')\n",
    "\n",
    "# Re-structure Vocabulary to a list so we can use indices to efficiently represent terms\n",
    "# Term_index will be used later in TfidfVectorizer\n",
    "Vocabulary = list(Vocabulary)\n",
    "Term_index = {w: idx for idx, w in enumerate(Vocabulary)}\n",
    "\n",
    "N = len(reviews_sentiment)\n",
    "\n",
    "print(f'Reuters documents count N= {N}')\n",
    "print(f'Vocabulary size= {len(Vocabulary)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7368b571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 43s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "Term_idf = defaultdict(int)\n",
    "for review in reviews_sentiment:\n",
    "    terms = set(tokenize(review))  # Count the document once\n",
    "    for term in terms:\n",
    "        Term_idf[term] += 1\n",
    "\n",
    "for term in Vocabulary:\n",
    "    # Do not forget to convert the count to float, i.e. \"1.0\" below\n",
    "    Term_idf[term] = log(N / (1.0 + Term_idf[term]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1794420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.339 script\n",
      "3.545 soundtrack\n",
      "2.596 actor\n",
      "0.604 film\n",
      "4.256 producer\n",
      "2.049 director\n",
      "2.660 special\n",
      "3.785 effect\n",
      "3.294 score\n",
      "6.235 cameraman\n",
      "5.413 editor\n",
      "8.422 blooper\n",
      "3.837 box\n",
      "4.058 office\n",
      "2.100 cast\n",
      "7.013 choreographer\n",
      "3.102 cinema\n",
      "0.506 movie\n",
      "3.642 theater\n",
      "8.740 costumer\n",
      "5.395 critic\n",
      "5.369 dubbing\n",
      "4.443 extra\n",
      "5.036 flashback\n",
      "5.440 flash\n",
      "3.786 forward\n",
      "6.128 grip\n",
      "9.721 hairstylist\n",
      "4.360 lighting\n",
      "4.387 negative\n",
      "8.517 outtake\n",
      "5.796 premiere\n",
      "3.720 sequel\n",
      "8.623 puppeteer\n",
      "5.850 reel\n",
      "1.886 scene\n",
      "2.559 set\n",
      "5.417 stunt\n",
      "1.891 man\n",
      "7.419 subtitle\n",
      "5.552 synopsis\n",
      "4.128 studio\n",
      "9.028 squib\n",
      "3.103 sound\n",
      "3.785 effect\n",
      "3.454 voice\n",
      "3.564 writer\n",
      "6.928 zoom\n",
      "In Reuters corpus:\n",
      "    min idf= 0.5059 'movie'\n",
      "    max idf= 10.1266 'perjurer'\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 64.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_keywords=['script', 'soundtrack', 'actor', 'film', 'producer', 'director', 'special', 'effect', 'score', 'cameraman', 'editor', 'blooper', 'box', 'office', 'cast', 'choreographer', 'cinema', 'movie', 'theater', 'costumer', 'critic', 'dubbing', 'extra', 'flashback', 'flash', 'forward', 'grip', 'hairstylist', 'lighting', 'negative', 'outtake', 'premiere', 'sequel', 'puppeteer', 'reel', 'scene', 'set', 'stunt', 'man', 'subtitle', 'synopsis', 'studio', 'squib', 'sound', 'effect', 'voice', 'writer', 'zoom']\n",
    "for t in list_keywords:\n",
    "    print(f'{Term_idf[t]:.3f} {t}')  \n",
    "mn_key = min(Term_idf, key=Term_idf.get)\n",
    "mx_key = max(Term_idf, key=Term_idf.get)\n",
    "print(f\"In Reuters corpus:\\n\\\n",
    "    min idf= {Term_idf[mn_key]:.4f} '{mn_key}'\\n\\\n",
    "    max idf= {Term_idf[mx_key]:.4f} '{mx_key}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315633fc",
   "metadata": {},
   "source": [
    "# 4. [20 pts] Group the reviews into two groups by {sentiment 0, 1} and list the most frequent 30 terms in these two groups. Do you suggest any word that can make a separation between sentiment 0 and 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f78f6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_0=[]\n",
    "sentiment_1=[]\n",
    "for review in reviews_sentiment_w_sent:\n",
    "    if(review[1] == \"0\"):\n",
    "        sentiment_0.append(review[0])\n",
    "    if(review[1] == \"1\"):\n",
    "        sentiment_1.append(review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8ed4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    terms = word_tokenize(text)\n",
    "    # all lower case\n",
    "    terms = [w.lower() for w in terms]\n",
    "    # filter stop words\n",
    "    terms = [w for w in terms if w not in Stop_words and not w.isdigit()]\n",
    "    # remove contractions, best way might be having a list \n",
    "    terms = [w for w in terms if not re.search(r'^\\W\\w+$', w)]\n",
    "    return terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5566ca48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22.4 s\n",
      "Wall time: 35 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>103997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>50117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>37595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>26283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>22458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>15254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>14728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>14726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>14007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>12358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>12355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>10753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>10185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>10136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>10117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>9469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>8801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>8539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>8353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>8313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <td>8214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acting</th>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>7780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>7353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watch</th>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>7184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>character</th>\n",
       "      <td>6980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "br          103997\n",
       "movie        50117\n",
       "film         37595\n",
       "one          26283\n",
       "like         22458\n",
       "even         15254\n",
       "good         14728\n",
       "bad          14726\n",
       "would        14007\n",
       "time         12358\n",
       "really       12355\n",
       "see          10753\n",
       "story        10185\n",
       "get          10136\n",
       "much         10117\n",
       "people        9469\n",
       "make          9355\n",
       "could         9300\n",
       "made          8801\n",
       "well          8539\n",
       "first         8353\n",
       "movies        8313\n",
       "plot          8214\n",
       "acting        8087\n",
       "way           7780\n",
       "characters    7353\n",
       "watch         7220\n",
       "also          7184\n",
       "think         7129\n",
       "character     6980"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cvec = CountVectorizer(stop_words=Stop_words)\n",
    "import pandas as pd\n",
    "\n",
    "X_cvec = cvec.fit_transform(sentiment_0)\n",
    "count_array = X_cvec.toarray()\n",
    "count_array=count_array.sum(axis=0)\n",
    "count_array = count_array.reshape(1, -1)\n",
    "df = pd.DataFrame(data=count_array,columns = cvec.get_feature_names_out())\n",
    "\n",
    "df=df.T\n",
    "df=df.sort_values(0,ascending=False)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81d845e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 33.4 s\n",
      "Wall time: 45.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br</th>\n",
       "      <td>97954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>42110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>37854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>27320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>17714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>15025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>12964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>12934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>12752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>12729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>12276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>10793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>10739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>10595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>8137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>7865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many</th>\n",
       "      <td>7627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>7601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>7161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>6996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "br          97954\n",
       "film        42110\n",
       "movie       37854\n",
       "one         27320\n",
       "like        17714\n",
       "good        15025\n",
       "great       12964\n",
       "story       12934\n",
       "time        12752\n",
       "well        12729\n",
       "see         12276\n",
       "also        10793\n",
       "really      10739\n",
       "would       10595\n",
       "even         9617\n",
       "first        9230\n",
       "much         9201\n",
       "people       8719\n",
       "love         8692\n",
       "best         8510\n",
       "get          8285\n",
       "life         8137\n",
       "way          7865\n",
       "many         7627\n",
       "films        7601\n",
       "made         7351\n",
       "think        7208\n",
       "two          7161\n",
       "characters   7103\n",
       "movies       6996"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cvec = CountVectorizer(stop_words=Stop_words)\n",
    "import pandas as pd\n",
    "\n",
    "X_cvec = cvec.fit_transform(sentiment_1)\n",
    "count_array = X_cvec.toarray()\n",
    "count_array=count_array.sum(axis=0)\n",
    "count_array = count_array.reshape(1, -1)\n",
    "df_2 = pd.DataFrame(data=count_array,columns = cvec.get_feature_names_out())\n",
    "\n",
    "df_2=df_2.T\n",
    "df_2=df_2.sort_values(0,ascending=False)\n",
    "df_2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f40b3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=df.head(30)[0].keys()\n",
    "l_2=df_2.head(30)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08a8b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad\n",
      "make\n",
      "could\n",
      "plot\n",
      "acting\n",
      "watch\n",
      "character\n"
     ]
    }
   ],
   "source": [
    "for entry in l:\n",
    "    if(entry not in l_2):\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58b83b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "love\n",
      "best\n",
      "life\n",
      "many\n",
      "films\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "for entry in l_2:\n",
    "    if(entry not in l):\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0998082",
   "metadata": {},
   "source": [
    "Some words that may work are great,love, best,life,many,films and to for differentiating between sentiment 1 and 0. Some words that may work for differentiating between sentiment 0 and 1 are bad,make,could,plot,acting, watch, and character. This is unsuprising in my opinion, as many of these words are frequently used describing positive or negative things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d12997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
